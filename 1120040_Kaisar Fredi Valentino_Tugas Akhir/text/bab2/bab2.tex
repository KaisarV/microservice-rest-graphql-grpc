%-----------------------------------------------------------------------------%
\chapter{LANDASAN TEORI}
%-----------------------------------------------------------------------------%
\vspace{4.5pt}

\section{Tinjauan Pustaka}
Pada tugas akhir ini, ada beberapa teori yang diperlukan. Pembahasan mengenai teori-teori akan dijelaskan sebagai berikut
\subsection{Arsitektur \textit{microservice}}
Arsitektur \textit{microservice} merujuk pada pendekatan pengembangan perangkat lunak yang terdiri dari beberapa layanan independen, terpisah, dan memiliki fungsionalitas yang terbatas. Arsitektur \textit{microservice} mengarahkan pada pemisahan komponen aplikasi terdistribusi menjadi entitas independen yang memfokuskan pada solusi dari masalah tertentu. Ini berarti bahwa sebuah \textit{microservice}, selama menyediakan fungsionalitasnya melalui pengiriman pesan, dapat diimplementasikan secara internal dengan menggunakan bahasa pemrograman yang berbeda pada setiap komponen aplikasi\cite{1}.\\
Beberapa masalah pada monolitik yang diselesaikan oleh arsitektur \textit{microservice} diantaranya\cite{1}:
\begin{enumerate}[nolistsep,leftmargin=0.5cm]
\item Arsitektur \textit{microservice} membatasi jumlah fungsionalitas yang diimplementasikan dalam satu layanan, sehingga menghasilkan kode yang lebih kecil dan membatasi risiko bug. Karena setiap layanan pada arsitektur \textit{microservice} independen, pengembang dapat menguji dan menyelidiki fungsionalitasnya secara terpisah dari sistem yang lain.
\item Perencanaan transisi yang bertahap ke versi baru dari suatu \textit{microservice} memungkinkan peningkatan yang lancar. Penyediaan versi baru dapat dilakukan dengan men-deploy sisi-sisi dengan yang lama, dan kemudian layanan yang bergantung pada yang lama dapat dimodifikasi secara bertahap agar dapat berinteraksi dengan versi baru tersebut. Hal ini dapat meningkatkan integrasi yang berkelanjutan dan mempermudah pemeliharaan perangkat lunak.
\item Perubahan modul pada arsitektur \textit{microservice} tidak membutuhkan reboot sistem secara keseluruhan. Hanya \textit{microservice}s pada modul tersebut yang perlu di-reboot. Karena ukuran \textit{microservice}s yang kecil, para pengembang dapat dengan mudah mengembangkan, menguji, dan memelihara layanan dengan waktu downtime yang singkat saat proses redeployment.
\item \textit{microservice}s secara alami cocok untuk dikontainerisasi, dan developer memiliki kebebasan yang tinggi dalam mengkonfigurasi lingkungan deployment yang paling sesuai dengan kebutuhan mereka, baik dari segi biaya maupun kualitas layanan.
\item Melakukan \textit{scaling} arsitektur \textit{microservice} tidak berarti harus menduplikasi semua komponennya, dan pengembang dapat dengan mudah menambah atau menghapus instance layanan yang berkaitan dengan beban kerja yang sedang dihadapi.
\item Arsitektur \textit{microservice} tidak memiliki kendala selain teknologi yang digunakan untuk menghubungkan layanan-layanan tersebut (media, protokol, \textit{encoding data}). Selain itu, arsitektur \textit{microservice} tidak memberikan keterikatan tambahan dan para pengembang dapat secara bebas memilih sumber daya optimal (bahasa pemrograman, kerangka kerja, dll.) untuk implementasi setiap layanan.
\end{enumerate}
\textit{Microservice} semakin populer karena membantu bisnis mencapai kesuksesan dalam menghadapi tekanan untuk beradaptasi, berubah, dan meningkatkan kinerja secara lebih sering dan cepat. Arsitektur \textit{microservice} memungkinkan perusahaan yang beroperasi di domain yang kompleks untuk memiliki fleksibilitas seperti perusahaan yang lebih kecil dan sederhana, namun tetap mempertahankan kekuatan dan jangkauan ukuran sebenarnya\cite{5}.\\

\subsection{\textit{REST}}
\textit{REST (Representational State Transfer)} adalah suatu arsitektur yang digunakan dalam pengembangan layanan web, yang berbasis pada protokol HTTP (Hypertext Transfer Protocol). \textit{REST} bekerja dengan menyediakan jalur atau endpoint untuk mengakses sumber daya (data), dan endpoint tersebut digunakan ketika \textit{client} ingin mengakses sumber daya tersebut. Hasil permintaan tersebut berupa representasi dari sumber daya, yang dapat berupa berbagai format data seperti \textit{JSON}, \textit{XML}, atau \textit{HTML}\cite{2}.\\
\textit{REST} juga menggunakan konsep statelessness, yang berarti setiap permintaan yang dikirim ke server harus membawa semua informasi yang diperlukan untuk memproses permintaan tersebut. \textit{client} harus menyimpan seluruh informasi terkait status aplikasi di sisi \textit{client}. \textit{client} harus mengirimkan informasi status ke server saat dibutuhkan. \textit{REST} memungkinkan \textit{client} dan server untuk beroperasi secara independen, sehingga informasi status dapat ditimpa dan seluruh data yang diambil dari server dapat dicache di sisi \textit{client} untuk meningkatkan performa keseluruhan\cite{2}.\\
Terdapat 6 batasan dari arsitektur \textit{REST}, diantaranya\cite{6} :
\begin{enumerate}[nolistsep,leftmargin=0.5cm]
\item Model \textit{Client-Server}, memisahkan tanggung jawab antara \textit{client} dan server, memungkinkan pengembangan \textit{client} dan server secara terpisah dan skalabilitas yang lebih baik.
\item \textit{Stateless}, komunikasi tidak memperbolehkan server menyimpan informasi tentang \textit{client}, sehingga meningkatkan skalabilitas tetapi juga meningkatkan data yang berulang dikirim dengan permintaan.
\item \textit{Cache}, memungkinkan merespons permintaan yang identik dengan respons yang disimpan, mengurangi konsumsi jaringan, dan meningkatkan skalabilitas.
\item \textit{Uniform interface}, memungkinkan arsitektur sistem yang lebih sederhana dan pemisahan implementasi komponen dari layanan yang mereka tawarkan.
\item Sistem Berlapis, terdiri dari lapisan hierarkis dan komponen pada setiap lapisan hanya dapat berinteraksi langsung dengan komponen pada lapisan di bawahnya, mengurangi kompleksitas sistem.
\item \textit{Code-On-Demand}, memungkinkan \textit{client} untuk mengunduh dan mengeksekusi kode dari server, memperluas kemampuan \textit{client}.
\\
\end{enumerate}


\subsection{\textit{GraphQL}}
\textit{GraphQL} merupakan sebuah bahasa kueri untuk API dan juga runtime yang berfungsi untuk memenuhi kueri tersebut dengan data yang sudah ada, dengan deskripsi data yang jelas dan mudah dipahami. Kelebihan \textit{GraphQL} adalah memungkinkan \textit{client} untuk meminta data yang diperlukan dan tidak terlalu banyak sehingga tidak terjadi \textit{over-fetching}. \textit{GraphQL} dikembangkan di \textit{Facebook} pada tahun 2012 karena pengambilan data saat itu tidak efektif untuk aplikasi seluler. \textit{GraphQL} kemudian dirilis sebagai proyek \textit{open-source} pada tahun 2015 dan sekarang telah digunakan oleh beberapa perusahaan besar seperti \textit{Airbnb}, \textit{GitHub}, \textit{Netflix}, dan \textit{Twitter}. Meskipun \textit{GraphQL} tidak terikat pada protokol tertentu, dalam praktiknya sering digunakan dengan HTTP yang mirip dengan \textit{REST}. Selain model permintaan-respon, \textit{GraphQL} juga menawarkan fitur subscriptions yang memungkinkan server untuk mengirim data secara aktif ke \textit{client}, yang biasanya diimplementasikan dengan menggunakan teknologi \textit{WebSockets}\cite{6}.\\
Dalam \textit{GraphQL}, \textit{client} dapat mengirim permintaan POST yang disesuaikan untuk mengambil hanya data yang dibutuhkan, sehingga memungkinkan \textit{client} untuk menentukan jenis data yang diambil dari database. Fitur ini sangat berguna ketika \textit{client} membutuhkan format respons yang fleksibel agar transfer data tidak berlebihan. \textit{GraphQL} didukung oleh berbagai bahasa pemrograman populer seperti \textit{Python}, \textit{C-Sharp}, dan \textit{JavaScript}. \textit{GraphQL} memiliki tiga bagian penting yang harus didefinisikan terlebih dahulu, yaitu mutasi yang digunakan untuk memperbarui, memasukkan, dan menghapus data, query untuk memanggil data, dan tipe untuk menggambarkan jenis \textit{field} atau data\cite{2}.\\

\subsection{\textit{gRPC}}
Salah satu jenis \textit{Remote Procedure Call (RPC)} yang populer dan terus dikembangkan adalah \textit{gRPC}, yang merupakan singkatan rekursif dari \textit{gRPC Remote Procedure Call} pada versi pertamanya. \textit{Google}, sebagai pengembang \textit{gRPC}, memiliki infrastruktur terdistribusi yang sangat besar, yang dibuktikan dengan pembangunan infrastruktur \textit{cloud} terbesar di dunia pada tahun 2016\cite{7}.\\

\textit{Google} menggunakan \textit{RPC} bernama \textit{Stubby} untuk menghubungkan berbagai layanan mikro dalam infrastruktur mereka. Pada tahun 2015, \textit{Google} memutuskan untuk mengembangkan versi baru dari \textit{Stubby} yang bersifat \textit{open-source} agar pengembang di seluruh dunia dapat berkontribusi. Versi baru tersebut kemudian dikenal sebagai \textit{gRPC}. Teknologi ini tidak hanya digunakan untuk layanan mikro dalam dan luar \textit{Google}, tetapi juga untuk ponsel, situs web, dan perangkat \textit{Internet of Things (IoT)}. Selain dianggap memiliki kinerja yang tinggi, \textit{gRPC} dapat mengatasi kekurangan dalam performa, kecepatan komunikasi, kenyamanan pengembang, dan keamanan komunikasi yang terdapat pada \textit{REST}\cite{8}.\\

\textit{gRPC} menggunakan \textit{protocol buffers} sebagai \textit{Interface Definition Language (IDL)} untuk mengatur serialisasi data, sedangkan \textit{REST} biasanya menggunakan \textit{JSON} sebagai \textit{IDL}. Sebelum menggunakan \textit{gRPC}, pengguna perlu mendefinisikan struktur data yang akan digunakan, lalu \textit{protocol buffers} akan digenerasikan secara otomatis dengan perintah khusus. Urutan struktur data sangat penting dalam \textit{protocol buffers}, dan penambahan atribut baru harus diletakkan di urutan terakhir sebelum menggenerasikan \textit{protocol buffers}.
\\\\

\section{Tinjauan Studi}
\par Pada Tabel \ref{tbl:StateoftheArt} diberikan penjelasan mengenai studi terkait dalam penelitian:

\begingroup
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}
\begin{small}
	\begin{longtable}{|p{0.5cm}|p{2.7cm}|p{3.2cm}|p{3.1cm}|p{2.5cm}|}
		\caption{Tinjauan Studi}\\
		\hline
		\textbf{No} & \textbf{Peneliti} & \textbf{Judul} & \textbf{Rumusan Masalah} & \textbf{Hasil}\\
		\endfirsthead
		
		\hline
		1 & Armin Lawi, Benny L. E. Panggabean, Takaichi Yoshida. & Evaluating GraphQL and REST API Services Performance in a Massive and Intensive Accessible Information System. & Melakukan evaluasi kinerja layanan API \textit{REST} dan \textit{GraphQL} dengan menguji kinerjanya pada sistem informasi manajemen yang sedang berjalan, yang banyak menghasilkan transaksi kueri yang kompleks pada sebuah database dengan banyak relasi. & \textit{REST} menggunakan beberapa \textit{endpoint} untuk meningkatkan kinerja saat mengambil data. \textit{GraphQL} cocok digunakan ketika persyaratan data sering berubah dan penggunaan sumber daya menjadi hal penting.\\
		
		\hline
		2 & Xian Jun Hong, Hyun Sik Yang,  Young Han Kim. & Performance Analysis of RESTful API and RabbitMQ for Microservice Web Application. & Analisis kinerja pada arsitektur microservice dan membandingkan kinerja antara sistem yang menggunakan RabbitMQ dan sistem yang menggunakan \textit{RESTful API}. & Sistem arsitektur \textit{microservice}  dengan \textit{RESTful API} mengalami ketidakstabilan ketika jumlah penggunanya melebihi 250 orang, sementara sistem yang menggunakan \textit{RabbitMQ} tetap stabil meskipun dengan jumlah pengguna yang sama.\\
		
		\hline
		3 & Riku Ala-Laurinaho, Joel Mattila, Juuso Autiosalo, Jani Hietala, Heikki Laaki, Kari Tammi. & Comparison of REST and GraphQL Interfaces for OPC UA. & Melakukan perbandingan karakteristik antarmuka \textit{REST} dan \textit{GraphQL} untuk protokol \textit{OPC UA} dan dilakukan pengukuran kinerja pada operasi membaca dan menulis data. & Hasil pengukuran memperlihatkan bahwa ketika menggunakan \textit{OPC UA} secara langsung tanpa perantara, kinerjanya lebih cepat bahkan jika \textit{client} perlu terlebih dahulu terhubung ke server \textit{OPC UA}. Namun, membaca satu nilai yang sudah tersimpan di \textit{cache} lebih cepat dibandingkan membaca nilai langsung dari server \textit{OPC UA}. Menulis ke server \textit{OPC UA} sedikit lebih cepat dibandingkan membaca satu nilai, tetapi ketika jumlah nilai yang dibaca bertambah, membaca akan menjadi lebih cepat.
		\label{tbl:StateoftheArt}\\
		\hline
	\end{longtable}
\end{small}
\endgroup

Pada bagian tinjauan pustaka, akan dibahas perbandingan hasil dari berbagai penelitian dan jurnal yang terkait dengan penggunaan teknologi \textit{REST} dan \textit{GraphQL}. Beberapa jurnal atau paper yang memiliki relevansi dengan tugas akhir ini dibahas dan dibandingkan melalui tabel state of the art yang telah disusun oleh penulis.\\

Peneliti pertama, Armin Lawi, et al. \cite{2} mengajukan sebuah metodologi penelitian baru untuk mengevaluasi kinerja layanan \textit{API} \textit{REST} dan \textit{GraphQL} dengan dua ide utama yang dianggap sebagai hal-hal baru dan berbeda dari pendekatan sebelumnya. Metode baru yang digunakan untuk mengevaluasi kinerja layanan \textit{API} \textit{REST} dan \textit{GraphQL} adalah dengan menguji kinerjanya pada sistem informasi manajemen yang sedang berjalan, yang banyak menghasilkan transaksi kueri yang kompleks pada sebuah database dengan banyak relasi. Sumber data untuk penelitian ini berasal dari data asli kueri transaksi pada SIM-LP2M, sebuah sistem informasi manajemen yang dijalankan oleh Institut Penelitian dan Pengabdian kepada Masyarakat di Universitas Hasanuddin.\\

Berdasarkan hasil pengujian \textit{response time}, dapat disimpulkan bahwa rata-rata \textit{response time} \textit{GraphQL} sebesar 1864,50 ms dengan rentang waktu 1810-2130 ms dan deviasi standar 75,78 ms. Sedangkan \textit{REST} memiliki waktu respons yang lebih cepat yaitu 922,85 ms dengan rentang waktu 890-1000 ms dan deviasi standar 32,99 ms. \textit{REST} memiliki \textit{response time} yang lebih cepat dan stabil pada setiap pengujian.\\

Pada pengujian \textit{throughput}, hasil evaluasi menunjukkan bahwa rata-rata \textit{throughput} untuk layanan yang menggunakan \textit{GraphQL} sebesar 2856,95 permintaan/ms dengan rentang antara 2666-3117 permintaan/ms dan standar deviasi sebesar 103,01 permintaan/ms, sedangkan layanan yang menggunakan \textit{REST} dapat menangani rata-rata 4546,45 permintaan/ms dengan rentang antara 4200-5175 permintaan/ms dan standar deviasi sebesar 201,18 permintaan/ms. \\

Selama 10 ms pertama dari eksperimen, hasilnya menunjukkan bahwa penggunaan CPU oleh layanan \textit{REST} mencapai puncak 82,5\% dan tetap fluktuatif ketika digunakan secara intensif, dengan rata-rata 75,50\% dalam rentang 70-82,45\%. Di sisi lain, layanan \textit{GraphQL} menunjukkan kestabilan yang konsisten dengan rata-rata penggunaan CPU sebesar 47,37\% dalam rentang 44,43-50\% dan standar deviasi 1,27\%.\\

Dalam pengujian konsumsi memori, hasil eksperimen menunjukkan bahwa rata-rata konsumsi memori \textit{REST} adalah 68,75 MB dalam rentang 57,50-79,47 MB dengan standar deviasi 6,06 MB, sedangkan pada \textit{GraphQL} adalah 41,43 MB dalam rentang 38,6-45,20 MB dengan standar deviasi 1,50 MB.entang 44,43-50\% dan standar deviasi 1,27\%.\\

Dalam hal kecepatan, \textit{REST} lebih cepat dengan \textit{response time} 51\% lebih cepat dan \textit{\textit{throughput}} 37\% lebih cepat. Untuk penggunaan sumber daya, \textit{GraphQL} lebih efisien dengan \textit{CPU load} 37\% lebih rendah dan penggunaan memori 40\% lebih rendah karena struktur prosesnya dapat mengelola permintaan pada satu \textit{endpoint}.\\

Dalam jurnal yang ditulis oleh Xian Jung Hong et al. \cite{9}, dilakukan pengujian terhadap performa sistem dengan menggunakan \textit{message broker RabbitMQ} dan sistem tradisional yang hanya menggunakan \textit{REST} API sebagai media komunikasi antar \textit{microservice}. Hasil pengujian menunjukkan bahwa sistem yang menggunakan \textit{RabbitMQ} (tanpa menggunakan \textit{API Gateway}) memiliki performa yang lebih stabil dan lebih baik dibandingkan dengan sistem yang tidak menggunakan \textit{RabbitMQ}. Dalam pengujian dengan jumlah pengguna yang berbeda, ketika jumlah pengguna melebihi 250, performa sistem menurun dan menyebabkan \textit{error rate} yang tinggi pada sistem tanpa \textit{RabbitMQ}. Namun, dengan menggunakan \textit{RabbitMQ}, sistem masih dapat berjalan dengan stabil dan memberikan \textit{throughput} yang lebih baik.\\

Jurnal yang ditulis oleh Riku Ala-Laurinaho, et al. \cite{6} membandingkan karakteristik antarmuka \textit{REST} dan \textit{GraphQL} untuk \textit{OPC UA} dan melakukan pengukuran pada pembacaan dan penulisan data. Ketika antarmuka web sudah terhubung ke server \textit{OPC UA}, \textit{GraphQL} memerlukan waktu 13\% lebih lama untuk membaca satu nilai dan 54\% lebih lama untuk menulis nilai dibandingkan dengan \textit{REST}. Namun, ketika ada beberapa nilai yang harus diambil, \textit{GraphQL} lebih unggul dibandingkan \textit{REST} dengan perbedaan yang signifikan. \textit{REST} memerlukan satu permintaan untuk setiap nilai, sehingga waktu rata-rata membaca dan menulis nilai masing-masing 268\% dan 24\% lebih lambat daripada \textit{GraphQL} yang dapat melakukan beberapa permintaan sekaligus. \textit{Cache server} dapat membantu mengurangi waktu membaca pada server \textit{REST}, dan pengambilan nilai dari \textit{cache} bahkan lebih cepat daripada membaca nilai langsung dari server \textit{OPC UA}. Namun, penggunaan \textit{cache server} juga dapat meningkatkan latensi jika cache tidak berisi nilai yang diminta dan server \textit{REST} harus membaca nilai dari server \textit{OPC UA}. Standar deviasi pengukuran cukup tinggi, terutama pada antarmuka \textit{REST}, dan pengukuran di mana server \textit{REST} harus terhubung terlebih dahulu ke server \textit{OPC UA} dikecualikan dari tabel. Waktu eksekusi permintaan pada server \textit{REST} yang tidak terhubung dapat memakan waktu lebih dari 1 detik untuk membaca/menulis satu nilai dan lebih dari 2,5 detik untuk membaca/menulis 50 nilai. Hasil pengukuran menunjukkan bahwa menggunakan \textit{OPC UA} secara langsung, tanpa antarmuka perantara, lebih cepat secara signifikan, bahkan ketika \textit{client} perlu terlebih dahulu terhubung ke server \textit{OPC UA}. Namun, membaca satu nilai yang sudah tersimpan di \textit{cache} lebih cepat dibandingkan membaca nilai langsung dari server \textit{OPC UA}. Menulis ke server \textit{OPC UA} sedikit lebih cepat dibandingkan membaca dengan satu nilai, tetapi membaca menjadi lebih cepat ketika jumlah nilai meningkat.\\



\section{Tinjauan Objek}
Pada bagian ini akan dijelaskan objek penelitian yang akan digunakan pada tugas akhir ini. Objek pada penelitian ini adalah membandingkan performa antara \textit{REST}, \textit{GraphQL}, dan \textit{gRPC} dalam lingkungan kontainerisasi dan non-kontainerisasi. Penelitian ini akan menggunakan projek \textit{e-commerce} bernama \textit{Digota}\cite{10}, dimana nantinya ketiga teknologi (\textit{REST}, \textit{GraphQL}, dan \textit{gRPC}) akan diterapkan. Penelitian ini akan memperhitungkan aspek-aspek seperti \textit{response time}, \textit{throughput}, \textit{CPU load}, dan pemanfaatan memori pada kedua antarmuka dalam konteks penggunaan di dalam wadah (containerized) dan tanpa wadah. \\